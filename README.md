# Malware-Detection using Machine Learning

## Overview
This is a Multi class classification problem in which there are nine different classes of malware that we need to classify a given a data point.
Objective: Predict the probability of each data-point belonging to each of the nine classes.

## Motivation
In the past few years, the malware industry has grown very rapidly that, the syndicates invest heavily in technologies to evade traditional protection, forcing the anti-malware groups/communities to build more robust softwares to detect and terminate these attacks. The major part of protecting a computer system from a malware attack is to identify whether a given piece of file/software is a malware. I was always curious to find out a way that how machine learning can be applied to antivirus softwares so that it can act as breakthrough in providing state of the art results in consumer experience.

## Data Overview
Source : https://www.kaggle.com/c/malware-classification/data
We are provided with a set of known malware files representing a mix of 9 different families.
For every malware, we have two files-
1) .asm file
2) .byte file

Total train dataset consist of 200GB data out of which 50Gb of data is .bytes files and 150GB of data is .asm files.
There are total 10,868 .bytes files and 10,868 asm files total 21,736 files.

There are 9 types of malwares (9 classes) in our given data:
- Ramnit
- Lollipop
- Kelihos_ver3
- Vundo
- Simda
- Tracur
- Kelihos_ver1
- Obfuscator.ACY
- Gatak

This is lots of Data for a single-box/computer. Therefore we have taken only the byte files into account and extracted features from it to create our model.
Content of typical byte file looks like-

00401000 00 00 80 40 40 28 00 1C 02 42 00 C4 00 20 04 20 

00401010 00 00 20 09 2A 02 00 00 00 00 8E 10 41 0A 21 01

00401020 40 00 02 01 00 90 21 00 32 40 00 1C 01 40 C8 18

00401030 40 82 02 63 20 00 00 09 10 01 02 21 00 82 00 04

00401040 82 20 08 83 00 08 00 00 00 00 02 00 60 80 10 80

00401050 18 00 00 20 A9 00 00 00 00 04 04 78 01 02 70 90
....

where 00401050 ------> corresponds to address
18 00 00 20 A9 00 00 00 00 04 04 78 01 02 70 90 -------> hexadecimal representation

## Installation
The Code is written in Python 3.8. If you don't have Python installed you can find it [here](https://www.python.org/downloads/). If you are using a lower version of Python you can upgrade using the pip package, ensuring you have the latest version of pip. To install the required packages and libraries, run this command in the project directory after [cloning](https://www.howtogeek.com/451360/how-to-clone-a-github-repository/) the repository:
```bash
pip install -r requirements.txt
```

## My Final Overall Approach
I only extracted 10,868 .bytes files from train.7z (which is ~50GB after extraction) in my local machine and then split this set into Train, CV and Test set with 64%,16%, 20% of data respectively. And from this split dataset, I did my entire analysis on the train and did the validation part on test and cv set.

I extracted following features from .byte file for prediction-
- Unigram of Byte Files
- Size of Byte Files
- Top 5000 Bi-Gram of Byte files

After merging all the above features, the merged dataframe that I got, and created a .csv file from that (i.e. with the regular to_csv() function).

I got the best logg loss(0.045422) with XGBoost (hyper param tuned with RandomizedSearchCV).

## Performance Metric
- Multi class log-loss
- Confusion matrix

